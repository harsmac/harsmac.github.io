<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Fairness vs. Robustness</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <header>
        <nav class="container nav">
            <div class="logo"><a href="index.html">HM</a></div>
            <ul class="nav-list">
                <li><a href="index.html">Home</a></li>
                <li><a href="#overview">Overview</a></li>
                <li><a href="#analysis">Analysis</a></li>
            </ul>
        </nav>
    </header>

    <main class="container">
        <section class="hero" id="overview">
            <h1>Fairness vs. Robustness</h1>
            <p class="tagline">Exploring the relationship between robustness and bias in modern AI</p>
        </section>

        <section class="section">
            <h2>Project Overview</h2>
            <p>
                This study examines whether adversarially robust models are also fair. We challenge
                the assumption that robustness automatically reduces bias and show that robust models can
                still exhibit systematic unfairness across demographic groups.
            </p>
            <p>
                We evaluate a range of models on benchmarks measuring both adversarial robustness and fairness
                metrics. The results highlight a tension between these objectives: increasing robustness does
                not necessarily improve fairness and may even exacerbate biases in certain contexts.
            </p>
        </section>

        <section class="section" id="analysis">
            <h2>Analysis &amp; Findings</h2>
            <img src="assets/project2.png" alt="Fairness vs Robustness" style="width:100%; max-height:300px; object-fit:cover; border-radius:var(--border-radius); margin-bottom:1rem;">
            <p>
                Use this space to describe your experimental setup, datasets, evaluation protocols and the
                insights gained from your analyses. Discuss how robustness was achieved, how fairness was
                quantified and the trade‑offs observed between these two qualities.
            </p>
            <p>
                <em>Note:</em> Feel free to supplement this page with charts, tables and references to
                publications. The more context you provide, the easier it will be for readers to understand
                the challenges of achieving both fairness and robustness simultaneously.
            </p>
        </section>

        <section class="section">
            <h2>Implications</h2>
            <p>
                Reflect on the broader implications of this work for deploying AI responsibly. Highlight
                potential mitigation strategies and research directions aimed at aligning robustness with
                fairness.
            </p>
        </section>

        <div class="section" style="text-align:center;">
            <a href="index.html" class="primary-btn">← Back to Home</a>
        </div>
    </main>

    <footer>
        <p>© 2025 Harshitha Machiraju. All rights reserved.</p>
    </footer>
</body>
</html>